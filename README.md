# NLP Assignments

This repository contains a series of assignments and projects completed as part of a course in Natural Language Processing. Each project explores different aspects of NLP, from text preprocessing to deep learning models.

## Table of Contents

- [Technologies Used](#technologies-used)
- [Projects](#projects)
  - [Assignment 1: Text Preprocessing](#assignment-1-text-preprocessing)
  - [Assignment 2: Word Similarity and Sentiment Analysis](#assignment-2-word-similarity-and-sentiment-analysis)
  - [Assignment 3: Sentiment Analysis with Deep Learning](#assignment-3-sentiment-analysis-with-deep-learning)
  - [Assignment 4: Medical Question Answering](#assignment-4-medical-question-answering)
- [Installation](#installation)
- [Usage](#usage)
- [Contributing](#contributing)
- [License](#license)

## Technologies Used

- Python
- Libraries: NLTK, BS4, TensorFlow, PyTorch, Transformers, FastText, ELMo, Word2Vec
- Tools: Jupyter Notebook, Visual Studio Code

## Projects

### Assignment 1: Text Preprocessing
Utilized regular expressions and BeautifulSoup (BS4) to parse HTML from the CSAIL website. Extracted emails and other data, providing insights into efficient text data preprocessing.

### Assignment 2: Word Similarity and Sentiment Analysis
Explored text preprocessing impacts on word similarity metrics and implemented sentiment analysis using various NLP models like Bag of Words, N-gram, and several machine learning classifiers (Naive Bayes, Logistic Regression, Random Forest, SVM, Perceptron).

### Assignment 3: Sentiment Analysis with Deep Learning
Developed models for sentiment analysis using LSTM (both uni and bidirectional) with different word embedding techniques such as Word2Vec, FastText, and ELMo. This assignment is marked as work in progress.

### Assignment 4: Medical Question Answering
Implemented a seq2seq paradigm using transformer models such as BERT, MobileBERT, and RoBERTa, fine-tuned for medical question answering. Contains a detailed report and evaluation metrics.

## Installation

Clone the repository to your local machine:
```bash
git clone https://github.com/yourusername/nlp-assignments.git
```

Navigate to the project directory:
```bash
cd nlp-assignments
```

Install the required dependencies (mentioned most of the cases) with pip or conda package manager

## Usage

To run a specific assignment, navigate to the assignment's directory, and run the Jupyter Notebook:
```bash
cd 'Assignment 1'
jupyter notebook TextPreprocessing.ipynb
```

Repeat similar steps for other assignments by changing the directory and notebook names accordingly.

## Contributing

Contributions are welcome! For major changes, please open an issue first to discuss what you would like to change.
