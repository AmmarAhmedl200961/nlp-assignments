{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rKgKqfLofL9L"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from itertools import combinations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxrpHWWsfX--"
      },
      "source": [
        "The problem is to match the user's free-form input against a pre-determined list of banks. For example, user input 'bawag bank' should be matched to 'BAWAG Group AG'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3nsmwxZKfaqO"
      },
      "outputs": [],
      "source": [
        "# List of banks to compare\n",
        "banks =   ['Sberbank Europe AG',\n",
        "          'BAWAG Group AG',\n",
        "          'Raiffeisenbankengruppe OÖ Verbund eGen',\n",
        "          'Raiffeisen Bank International AG',\n",
        "          'Volksbanken Verbund',\n",
        "          'Erste Group Bank AG',\n",
        "          'KBC Groep',\n",
        "          'Investeringsmaatschappij Argenta',\n",
        "          'Belfius Bank',\n",
        "          'AXA Bank Belgium',\n",
        "          'The Bank of New York Mellon SA/NV',\n",
        "          'First Investment Bank AD',\n",
        "          'RCB Bank Ltd',\n",
        "          'Bank of Cyprus Holdings Public Limited Company',\n",
        "          'Hellenic Bank Public Company Limited',\n",
        "          'DekaBank Deutsche Girozentrale',\n",
        "          'Erwerbsgesellschaft der S-Finanzgruppe mbH & Co. KG',\n",
        "          'UBS Europe SE',\n",
        "          'DEUTSCHE APOTHEKER- UND ÄRZTEBANK EG',\n",
        "          'Volkswagen Bank Gesellschaft mit beschränkter Haftung',\n",
        "          'Münchener Hypothekenbank eG',\n",
        "          'DZ BANK AG Deutsche Zentral-Genossenschaftsbank, Frankfurt am Main',\n",
        "          'HASPA Finanzholding',\n",
        "          'State Street Europe Holdings Germany S.a.r.l. & Co. KG',\n",
        "          'J.P. Morgan AG',\n",
        "          'DEUTSCHE BANK AKTIENGESELLSCHAFT',\n",
        "          'COMMERZBANK Aktiengesellschaft',\n",
        "          'Landesbank Baden-Württemberg',\n",
        "          'Landesbank Hessen-Thüringen Girozentrale',\n",
        "          'Norddeutsche Landesbank - Girozentrale -',\n",
        "          'Deutsche Pfandbriefbank AG',\n",
        "          'Aareal Bank AG',\n",
        "          'Hamburg Commercial Bank AG',\n",
        "          'Bayerische Landesbank',\n",
        "          'Jyske Bank A/S',\n",
        "          'Sydbank A/S',\n",
        "          'Nykredit Realkredit A/S',\n",
        "          'Danske Bank A/S',\n",
        "          'Luminor Holding AS',\n",
        "          'Abanca Corporacion Bancaria S.A.',\n",
        "          'Banco Santander S.A.',\n",
        "          'Ibercaja Banco S.A.',\n",
        "          'Kutxabank S.A',\n",
        "          'Unicaja Banco S.A.',\n",
        "          'CaixaBank S.A.',\n",
        "          'Banco de Crédito Social Cooperativo',\n",
        "          'Banco Bilbao Vizcaya Argentaria S.A.',\n",
        "          'Banco de Sabadell S.A.',\n",
        "          'Bankinter S.A.',\n",
        "          'Kuntarahoitus Oyj',\n",
        "          'Nordea Bank Abp',\n",
        "          'OP Osuuskunta',\n",
        "          'SFIL',\n",
        "          'RCI Banque',\n",
        "          'Confédération Nationale du Crédit Mutuel',\n",
        "          'La Banque Postale',\n",
        "          'Bpifrance',\n",
        "          \"C.R.H. - Caisse de refinancement de l'habitat\",\n",
        "          'HSBC Continental Europe',\n",
        "          'Groupe BPCE',\n",
        "          'Groupe Crédit Agricole',\n",
        "          'Société générale',\n",
        "          'BNP Paribas',\n",
        "          'ALPHA SERVICES AND HOLDINGS S.A.',\n",
        "          'National Bank of Greece S.A.',\n",
        "          'Eurobank Ergasias Services and Holdings S.A.',\n",
        "          'Piraeus Financial Holdings',\n",
        "          'OTP-csoport',\n",
        "          'Magyar Bankholding',\n",
        "          'Barclays Bank Ireland plc',\n",
        "          'Citibank Holdings Ireland Limited',\n",
        "          'AIB Group plc',\n",
        "          'Bank of Ireland Group plc',\n",
        "          'Ulster Bank Ireland Designated Activity Company',\n",
        "          'Bank of America Europe Designated Activity Company',\n",
        "          'Íslandsbanki hf.',\n",
        "          'Landsbankinn hf.',\n",
        "          'Arion banki hf',\n",
        "          'Intesa Sanpaolo S.p.A.',\n",
        "          'Gruppo Bancario Finecobank  ',\n",
        "          'UniCredit S.p.A.',\n",
        "          'Gruppo Bancario Mediolanum  ',\n",
        "          'Credito Emiliano Holding S.p.A.',\n",
        "          'Banco BPM SpA',\n",
        "          'Banca Popolare di Sondrio, Società Cooperativa per Azioni',\n",
        "          'Banca Monte dei Paschi di Siena S.p.A.',\n",
        "          'CASSA CENTRALE BANCA',\n",
        "          'ICCREA BANCA S.P.A.',\n",
        "          'Mediobanca - Banca di Credito Finanziario S.p.A.',\n",
        "          'Akcine bendrove Šiauliu bankas',\n",
        "          'Precision Capital S.A.',\n",
        "          'RBC Investor Services Bank S.A.',\n",
        "          'J.P. Morgan Bank Luxembourg S.A.',\n",
        "          'Banque Internationale à Luxembourg',\n",
        "          'Banque et Caisse d´Epargne de l´Etat, Luxembourg',\n",
        "          'Akciju sabiedriba \"Citadele banka\"',\n",
        "          'MDB Group Limited',\n",
        "          'Bank of Valletta Plc',\n",
        "          'HSBC Bank Malta p.l.c.',\n",
        "          'BNG Bank N.V.',\n",
        "          'ING Groep N.V.',\n",
        "          'LP Group B.V.',\n",
        "          'de Volksbank N.V.',\n",
        "          'ABN AMRO Bank N.V.',\n",
        "          'Coöperatieve Rabobank U.A.',\n",
        "          'Nederlandse Waterschapsbank N.V.',\n",
        "          'Bank Polska Kasa Opieki S.A.',\n",
        "          'Powszechna Kasa Oszczednosci Bank Polski S.A.',\n",
        "          'LSF Nani Investments S.à r.l.',\n",
        "          'Banco Comercial Português SA',\n",
        "          'Caixa Geral de Depósitos SA',\n",
        "          'Banca Transilvania',\n",
        "          'Länförsäkringar Bank AB (publ)',\n",
        "          'Kommuninvest - group',\n",
        "          'Skandinaviska Enskilda Banken - group',\n",
        "          'SBAB Bank AB - group',\n",
        "          'Swedbank - group',\n",
        "          'Svenska Handelsbanken - group',\n",
        "          'Biser Topco S.à r.l.',\n",
        "          'Nova Ljubljanska Banka d.d. Ljubljana']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Va8q_kphfm2O"
      },
      "outputs": [],
      "source": [
        "# Examples of search strings\n",
        "s1 = 'Bawag bank' # other options: 'Bawag bank', 'Erste', 'Raiffaisen bank'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GaIKgI5Zf6y9",
        "outputId": "331bd468-75eb-439e-9434-33595ae4e0de"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bank 1</th>\n",
              "      <th>Bank 2</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Bawag bank</td>\n",
              "      <td>Belfius Bank</td>\n",
              "      <td>0.454545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Bawag bank</td>\n",
              "      <td>RCB Bank Ltd</td>\n",
              "      <td>0.454545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Bawag bank</td>\n",
              "      <td>Bayerische Landesbank</td>\n",
              "      <td>0.451613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Bawag bank</td>\n",
              "      <td>Kutxabank S.A</td>\n",
              "      <td>0.434783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Bawag bank</td>\n",
              "      <td>BNG Bank N.V.</td>\n",
              "      <td>0.434783</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Bank 1                 Bank 2     Score\n",
              "8   Bawag bank           Belfius Bank  0.454545\n",
              "12  Bawag bank           RCB Bank Ltd  0.454545\n",
              "33  Bawag bank  Bayerische Landesbank  0.451613\n",
              "42  Bawag bank          Kutxabank S.A  0.434783\n",
              "99  Bawag bank          BNG Bank N.V.  0.434783"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# A naive search method which you need to improve\n",
        "from difflib import SequenceMatcher\n",
        "res = []\n",
        "for token in banks:\n",
        "  res.append([s1, token, SequenceMatcher(None, s1, token).ratio()])\n",
        "\n",
        "df2 = pd.DataFrame(res, columns=['Bank 1', 'Bank 2', 'Score'])\n",
        "# The outcome is not great, for this search query 'BAWAG Group AG' should have highest similarity\n",
        "df2.sort_values(by=['Score'], ascending=[False]).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "TXc8yBZOhIH0",
        "outputId": "fbe6efd4-2868-446d-f49d-fea1aca1020b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bank 1</th>\n",
              "      <th>Bank 2</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bawag bank</td>\n",
              "      <td>BAWAG Group AG</td>\n",
              "      <td>0.166667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Bank 1          Bank 2     Score\n",
              "1  Bawag bank  BAWAG Group AG  0.166667"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " #The desired combination has a low score\n",
        "idx = df2['Bank 2'].isin(['BAWAG Group AG'])\n",
        "\n",
        "df2[idx].sort_values(by=['Score'], ascending=[False]).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Q1 Improve the similarity function for matching query entered by user with a predefined list of bank names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bank 1</th>\n",
              "      <th>Bank 2</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BAWAG Group AG</td>\n",
              "      <td>bawag bank</td>\n",
              "      <td>0.663232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Jyske Bank A/S</td>\n",
              "      <td>bawag bank</td>\n",
              "      <td>0.168777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Belfius Bank</td>\n",
              "      <td>bawag bank</td>\n",
              "      <td>0.168777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>BNG Bank N.V.</td>\n",
              "      <td>bawag bank</td>\n",
              "      <td>0.168777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Danske Bank A/S</td>\n",
              "      <td>bawag bank</td>\n",
              "      <td>0.168777</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Bank 1      Bank 2     Score\n",
              "1    BAWAG Group AG  bawag bank  0.663232\n",
              "34   Jyske Bank A/S  bawag bank  0.168777\n",
              "8      Belfius Bank  bawag bank  0.168777\n",
              "99    BNG Bank N.V.  bawag bank  0.168777\n",
              "37  Danske Bank A/S  bawag bank  0.168777"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# our improvements (preprocessing text)\n",
        "from difflib import SequenceMatcher\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re\n",
        "\n",
        "# Function to preprocess the text\n",
        "def preprocess(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove special characters\n",
        "    text = re.sub(r'\\W', ' ', text)\n",
        "    # Remove spaces\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "# Preprocess the texts and query\n",
        "preprocessed_texts = [preprocess(bank) for bank in banks]\n",
        "preprocessed_query = preprocess(s1)\n",
        "\n",
        "# Create a TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform the preprocessed texts\n",
        "tfidf_matrix = vectorizer.fit_transform(preprocessed_texts)\n",
        "\n",
        "# Compute the cosine similarity between the query and each text\n",
        "similarities = cosine_similarity(tfidf_matrix, vectorizer.transform([preprocessed_query]))\n",
        "\n",
        "\n",
        "# Create a DataFrame with the results\n",
        "res = []\n",
        "for i, s1 in enumerate(banks):\n",
        "    similarity = similarities[i][0]\n",
        "    res.append([s1, preprocessed_query, similarity])\n",
        "\n",
        "df2 = pd.DataFrame(res, columns=[\"Bank 1\", \"Bank 2\", \"Score\"])\n",
        "\n",
        "# Sort by similarity score in descending order\n",
        "df2_sorted = df2.sort_values(by=[\"Score\"], ascending=False)\n",
        "\n",
        "df2.sort_values(by=['Score'], ascending=[False]).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bank 1</th>\n",
              "      <th>Bank 2</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BAWAG Group AG</td>\n",
              "      <td>bawag bank</td>\n",
              "      <td>0.663232</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Bank 1      Bank 2     Score\n",
              "1  BAWAG Group AG  bawag bank  0.663232"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " #The desired combination has now highest score\n",
        "idx = df2['Bank 1'].isin(['BAWAG Group AG'])\n",
        "\n",
        "df2[idx].sort_values(by=['Score'], ascending=[False]).head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Our scores have improved !!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Q2 - Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "      <th>Unnamed: 4</th>\n",
              "      <th>Unnamed: 5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>623495523</td>\n",
              "      <td>1</td>\n",
              "      <td>Mon Dec 01 20:46:01 +0000 2014</td>\n",
              "      <td>WTF MY BATTERY WAS 31% ONE SECOND AGO AND NOW ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>623495527</td>\n",
              "      <td>1</td>\n",
              "      <td>Mon Dec 01 21:09:50 +0000 2014</td>\n",
              "      <td>@apple Contact sync between Yosemite and iOS8 ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>623495529</td>\n",
              "      <td>1</td>\n",
              "      <td>Mon Dec 01 21:35:14 +0000 2014</td>\n",
              "      <td>WARNING IF YOU BUY AN IPHONE 5S UNLOCKED FROM ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>623495536</td>\n",
              "      <td>1</td>\n",
              "      <td>Mon Dec 01 23:55:55 +0000 2014</td>\n",
              "      <td>@Apple, For the love of GAWD, CENTER the '1'on...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>623495537</td>\n",
              "      <td>1</td>\n",
              "      <td>Tue Dec 02 00:06:05 +0000 2014</td>\n",
              "      <td>i get the storage almost full notification lit...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id sentiment                            date  \\\n",
              "0  623495523         1  Mon Dec 01 20:46:01 +0000 2014   \n",
              "1  623495527         1  Mon Dec 01 21:09:50 +0000 2014   \n",
              "2  623495529         1  Mon Dec 01 21:35:14 +0000 2014   \n",
              "3  623495536         1  Mon Dec 01 23:55:55 +0000 2014   \n",
              "4  623495537         1  Tue Dec 02 00:06:05 +0000 2014   \n",
              "\n",
              "                                                text  Unnamed: 4  Unnamed: 5  \n",
              "0  WTF MY BATTERY WAS 31% ONE SECOND AGO AND NOW ...         NaN         NaN  \n",
              "1  @apple Contact sync between Yosemite and iOS8 ...         NaN         NaN  \n",
              "2  WARNING IF YOU BUY AN IPHONE 5S UNLOCKED FROM ...         NaN         NaN  \n",
              "3  @Apple, For the love of GAWD, CENTER the '1'on...         NaN         NaN  \n",
              "4  i get the storage almost full notification lit...         NaN         NaN  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df= pd.read_csv('Q2 Sentiment Analysis Dataset.csv', encoding='latin-1')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['1', '3', '5', 'not_relevant'], dtype=object)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sentiment.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Label encode the 'sentiment' column\n",
        "label_encoder = LabelEncoder()\n",
        "df['sentiment'] = label_encoder.fit_transform(df['sentiment'])\n",
        "\n",
        "df.sentiment.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sentiment= 0\n",
            "['WTF MY BATTERY WAS 31% ONE SECOND AGO AND NOW IS 29% WTF IS THIS @apple']\n",
            "sentiment= 1\n",
            "['#AAPL:The 10 best Steve Jobs emails ever...http://t.co/82G1kL94tx']\n",
            "sentiment= 2\n",
            "['Top 3 all @Apple #tablets. Damn right! http://t.co/RJiGn2JUuB']\n",
            "sentiment= 3\n",
            "['@Apple John Cantlie has been a prisoner of ISIS for 739 days, show you have not abandoned him. Sign https://t.co/WTn4fuiJ0P']\n"
          ]
        }
      ],
      "source": [
        "# see one of each sentiments retrieved\n",
        "sentiments = df.sentiment.unique().tolist()\n",
        "\n",
        "for sentiment in sentiments:\n",
        "    print('sentiment=',sentiment)\n",
        "    text = df[df.sentiment == sentiment].head(1).text.tolist()\n",
        "    print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                 wtf battery one second ago wtf apple\n",
              "1    apple contact sync yosemite io seriously screw...\n",
              "2    warning buy iphone unlocked apple iphone use v...\n",
              "3    apple love gawd center damn calendar app fixed...\n",
              "4    get storage almost full notification literally...\n",
              "Name: text, dtype: object"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# preprocess sentiments\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "def preprocess(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = text.strip()\n",
        "    text = word_tokenize(text)\n",
        "    text = [word for word in text if word not in stopwords.words('english')]\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    text = [lemmatizer.lemmatize(word) for word in text]\n",
        "    text = ' '.join(text)\n",
        "    return text\n",
        "\n",
        "# drop last 2 columns as they are unnamed\n",
        "df = df.drop(df.columns[[-1,-2]], axis=1)\n",
        "df['text'] = df['text'].apply(preprocess)\n",
        "\n",
        "df.text.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# splitting data into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Implement following feature extraction methods.\n",
        "- BoW based on raw counts **using Vectorizer**\n",
        "- BoW based on TfIDF **using transformer**\n",
        "- ngrams (unigrams, bigrams, trigrams)\n",
        "  \n",
        "Use following classifiers: Naïve Bayes, Logistic Regression, Random Forest, SVM, Perceptron.\n",
        "Calculate accuracy, Precision, Recall and F-score for all classifiers and report the results in tables. Make a\n",
        "table for multiclass classification results for different classification algorithms. Report both micro\n",
        "average and macro average of all measures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature Extractor has finished: BoW based on raw counts ...\n",
            "Feature Extractor has finished: BoW based on TfIDF ...\n",
            "Feature Extractor has finished: BoW based on raw counts Unigram ...\n",
            "Feature Extractor has finished: BoW based on raw counts Bigram ...\n",
            "Feature Extractor has finished: BoW based on raw counts Trigram ...\n",
            "Feature Extractor has finished: BoW based on TfIDF Unigram ...\n",
            "Feature Extractor has finished: BoW based on TfIDF Bigram ...\n",
            "Feature Extractor has finished: BoW based on TfIDF Trigram ...\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Initialize defaultdict of lists\n",
        "results = defaultdict(list)\n",
        "\n",
        "# List of feature extraction methods\n",
        "feature_extractors = [\n",
        "    ('BoW based on raw counts', CountVectorizer()),\n",
        "    ('BoW based on TfIDF', TfidfVectorizer(use_idf=True)),\n",
        "    ('BoW based on raw counts Unigram', CountVectorizer(ngram_range=(1, 1))),\n",
        "    ('BoW based on raw counts Bigram', CountVectorizer(ngram_range=(1, 2))),\n",
        "    ('BoW based on raw counts Trigram', CountVectorizer(ngram_range=(1, 3))),\n",
        "    ('BoW based on TfIDF Unigram', TfidfVectorizer(ngram_range=(1, 1), use_idf=True)),\n",
        "    ('BoW based on TfIDF Bigram', TfidfVectorizer(ngram_range=(1, 2), use_idf=True)),\n",
        "    ('BoW based on TfIDF Trigram', TfidfVectorizer(ngram_range=(1, 3), use_idf=True))\n",
        "]\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression, Perceptron\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# List of models\n",
        "models = [\n",
        "    ('Naive Bayes', MultinomialNB()),\n",
        "    ('Logistic Regression', LogisticRegression()),\n",
        "    ('Random Forest', RandomForestClassifier()),\n",
        "    ('Support Vector Machine', SVC()),\n",
        "    ('Perceptron', Perceptron())\n",
        "]\n",
        "\n",
        "# Iterate over feature extraction methods\n",
        "for extractor_name, extractor in feature_extractors:\n",
        "    # Fit and transform data\n",
        "    extractor.fit(train.text)\n",
        "    X_train = extractor.transform(train.text)\n",
        "    X_test = extractor.transform(test.text)\n",
        "\n",
        "    # Iterate over models\n",
        "    for model_name, model in models:\n",
        "        model.fit(X_train, train.sentiment)\n",
        "        y_pred = model.predict(X_test)\n",
        "        \n",
        "        # Get precision, recall, f1-score for each class\n",
        "        precision, recall, fscore, _ = precision_recall_fscore_support(test.sentiment, y_pred, average=None)\n",
        "        \n",
        "        # Calculate micro average (weighted average, takes class imbalance into account)\n",
        "        micro_avg_precision = np.average(precision, weights=np.bincount(test.sentiment))\n",
        "        micro_avg_recall = np.average(recall, weights=np.bincount(test.sentiment))\n",
        "        micro_avg_fscore = np.average(fscore, weights=np.bincount(test.sentiment))\n",
        "        \n",
        "        # Calculate macro average (simple average, treats all classes equally)\n",
        "        macro_avg_precision = np.mean(precision)\n",
        "        macro_avg_recall = np.mean(recall)\n",
        "        macro_avg_fscore = np.mean(fscore)\n",
        "        \n",
        "        # Append results to defaultdict\n",
        "        results['Feature Extractor'].append(extractor_name)\n",
        "        results['Model'].append(model_name)\n",
        "        results['Accuracy'].append((model.score(X_test, test.sentiment)))\n",
        "        results['Micro Avg Precision'].append(micro_avg_precision)\n",
        "        results['Micro Avg Recall'].append(micro_avg_recall)\n",
        "        results['Micro Avg F1 Score'].append(micro_avg_fscore)\n",
        "        results['Macro Avg Precision'].append(macro_avg_precision)\n",
        "        results['Macro Avg Recall'].append(macro_avg_recall)\n",
        "        results['Macro Avg F1 Score'].append(macro_avg_fscore)\n",
        "        \n",
        "    print('Feature Extractor has finished:', extractor_name, '...')\n",
        "        \n",
        "        \n",
        "# Convert defaultdict to DataFrame and send to results csv\n",
        "pd.DataFrame(results).to_csv('results.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature Extractor: BoW based on raw counts\n",
            "                 Model  Accuracy  Micro Avg Precision  Micro Avg Recall\n",
            "           Naive Bayes  0.721080             0.690453          0.721080\n",
            "   Logistic Regression  0.750643             0.736318          0.750643\n",
            "         Random Forest  0.727506             0.716887          0.727506\n",
            "Support Vector Machine  0.733933             0.742247          0.733933\n",
            "            Perceptron  0.724936             0.720074          0.724936\n",
            "\n",
            " Micro Avg F1 Score  Macro Avg Precision  Macro Avg Recall  Macro Avg F1 Score\n",
            "           0.694620             0.470212          0.424434            0.420932\n",
            "           0.728255             0.545820          0.454725            0.472255\n",
            "           0.701843             0.508775          0.431936            0.447706\n",
            "           0.700522             0.588395          0.420354            0.434046\n",
            "           0.714630             0.553251          0.506716            0.518738\n",
            "\n",
            "Feature Extractor: BoW based on TfIDF\n",
            "                 Model  Accuracy  Micro Avg Precision  Micro Avg Recall\n",
            "           Naive Bayes  0.737789             0.739775          0.737789\n",
            "   Logistic Regression  0.740360             0.727273          0.740360\n",
            "         Random Forest  0.726221             0.715088          0.726221\n",
            "Support Vector Machine  0.742931             0.743892          0.742931\n",
            "            Perceptron  0.718509             0.714300          0.718509\n",
            "\n",
            " Micro Avg F1 Score  Macro Avg Precision  Macro Avg Recall  Macro Avg F1 Score\n",
            "           0.699505             0.584496          0.412983            0.413118\n",
            "           0.711572             0.541052          0.431920            0.443830\n",
            "           0.698965             0.522850          0.427485            0.443430\n",
            "           0.710965             0.576615          0.427708            0.440612\n",
            "           0.711509             0.527130          0.482520            0.498652\n",
            "\n",
            "Feature Extractor: BoW based on raw counts Unigram\n",
            "                 Model  Accuracy  Micro Avg Precision  Micro Avg Recall\n",
            "           Naive Bayes  0.721080             0.690453          0.721080\n",
            "   Logistic Regression  0.750643             0.736318          0.750643\n",
            "         Random Forest  0.727506             0.713421          0.727506\n",
            "Support Vector Machine  0.733933             0.742247          0.733933\n",
            "            Perceptron  0.724936             0.720074          0.724936\n",
            "\n",
            " Micro Avg F1 Score  Macro Avg Precision  Macro Avg Recall  Macro Avg F1 Score\n",
            "           0.694620             0.470212          0.424434            0.420932\n",
            "           0.728255             0.545820          0.454725            0.472255\n",
            "           0.701674             0.500059          0.429821            0.443946\n",
            "           0.700522             0.588395          0.420354            0.434046\n",
            "           0.714630             0.553251          0.506716            0.518738\n",
            "\n",
            "Feature Extractor: BoW based on raw counts Bigram\n",
            "                 Model  Accuracy  Micro Avg Precision  Micro Avg Recall\n",
            "           Naive Bayes  0.737789             0.716654          0.737789\n",
            "   Logistic Regression  0.746787             0.733432          0.746787\n",
            "         Random Forest  0.723650             0.719530          0.723650\n",
            "Support Vector Machine  0.731362             0.742478          0.731362\n",
            "            Perceptron  0.736504             0.730673          0.736504\n",
            "\n",
            " Micro Avg F1 Score  Macro Avg Precision  Macro Avg Recall  Macro Avg F1 Score\n",
            "           0.706477             0.525813          0.427736            0.425919\n",
            "           0.720930             0.539608          0.441248            0.455830\n",
            "           0.696333             0.525213          0.428370            0.446579\n",
            "           0.694214             0.583559          0.411327            0.421590\n",
            "           0.717692             0.569816          0.464707            0.491390\n",
            "\n",
            "Feature Extractor: BoW based on raw counts Trigram\n",
            "                 Model  Accuracy  Micro Avg Precision  Micro Avg Recall\n",
            "           Naive Bayes  0.733933             0.705706          0.733933\n",
            "   Logistic Regression  0.742931             0.729588          0.742931\n",
            "         Random Forest  0.726221             0.724400          0.726221\n",
            "Support Vector Machine  0.722365             0.744389          0.722365\n",
            "            Perceptron  0.692802             0.686621          0.692802\n",
            "\n",
            " Micro Avg F1 Score  Macro Avg Precision  Macro Avg Recall  Macro Avg F1 Score\n",
            "           0.703398             0.500438          0.425621            0.423493\n",
            "           0.716210             0.537530          0.438044            0.452679\n",
            "           0.698058             0.530008          0.427060            0.445227\n",
            "           0.682660             0.600274          0.401858            0.410511\n",
            "           0.689143             0.506962          0.490272            0.497231\n",
            "\n",
            "Feature Extractor: BoW based on TfIDF Unigram\n",
            "                 Model  Accuracy  Micro Avg Precision  Micro Avg Recall\n",
            "           Naive Bayes  0.737789             0.739775          0.737789\n",
            "   Logistic Regression  0.740360             0.727273          0.740360\n",
            "         Random Forest  0.731362             0.718966          0.731362\n",
            "Support Vector Machine  0.742931             0.743892          0.742931\n",
            "            Perceptron  0.718509             0.714300          0.718509\n",
            "\n",
            " Micro Avg F1 Score  Macro Avg Precision  Macro Avg Recall  Macro Avg F1 Score\n",
            "           0.699505             0.584496          0.412983            0.413118\n",
            "           0.711572             0.541052          0.431920            0.443830\n",
            "           0.703162             0.517647          0.427344            0.441910\n",
            "           0.710965             0.576615          0.427708            0.440612\n",
            "           0.711509             0.527130          0.482520            0.498652\n",
            "\n",
            "Feature Extractor: BoW based on TfIDF Bigram\n",
            "                 Model  Accuracy  Micro Avg Precision  Micro Avg Recall\n",
            "           Naive Bayes  0.722365             0.740124          0.722365\n",
            "   Logistic Regression  0.737789             0.732189          0.737789\n",
            "         Random Forest  0.717224             0.703698          0.717224\n",
            "Support Vector Machine  0.733933             0.731694          0.733933\n",
            "            Perceptron  0.722365             0.713109          0.722365\n",
            "\n",
            " Micro Avg F1 Score  Macro Avg Precision  Macro Avg Recall  Macro Avg F1 Score\n",
            "           0.680267             0.589416          0.396902            0.400260\n",
            "           0.707795             0.566888          0.429000            0.439542\n",
            "           0.689872             0.507096          0.421582            0.436433\n",
            "           0.700079             0.561151          0.417575            0.426239\n",
            "           0.714874             0.523579          0.492707            0.502230\n",
            "\n",
            "Feature Extractor: BoW based on TfIDF Trigram\n",
            "                 Model  Accuracy  Micro Avg Precision  Micro Avg Recall\n",
            "           Naive Bayes  0.712082             0.756602          0.712082\n",
            "   Logistic Regression  0.737789             0.731051          0.737789\n",
            "         Random Forest  0.724936             0.719950          0.724936\n",
            "Support Vector Machine  0.726221             0.724107          0.726221\n",
            "            Perceptron  0.735219             0.724733          0.735219\n",
            "\n",
            " Micro Avg F1 Score  Macro Avg Precision  Macro Avg Recall  Macro Avg F1 Score\n",
            "           0.666971             0.634252          0.387512            0.391881\n",
            "           0.706384             0.562617          0.425797            0.434483\n",
            "           0.696174             0.539576          0.423698            0.440290\n",
            "           0.690509             0.551899          0.409053            0.415930\n",
            "           0.726004             0.552145          0.497246            0.516888\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for feature_extractor in df['Feature Extractor'].unique():\n",
        "    print('Feature Extractor:', feature_extractor)\n",
        "    # print everything after Model\n",
        "    df_filtered = df[df['Feature Extractor'] == feature_extractor].iloc[:, 1:]\n",
        "    half_length = len(df_filtered.columns) // 2\n",
        "    first_half = df_filtered.iloc[:, :half_length].to_string(index=False)\n",
        "    second_half = df_filtered.iloc[:, half_length:].to_string(index=False)\n",
        "    print(first_half)\n",
        "    print()\n",
        "    print(second_half)\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
