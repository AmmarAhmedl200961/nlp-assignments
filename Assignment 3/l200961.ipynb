{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1) Sentiment analysis using deep learning**\n",
    "\n",
    "This question uses following dataset of Urdu sentiment analysis. The class labels are P(positive)\n",
    "and N (Negative)\n",
    "\n",
    "https://github.com/MuhammadYaseenKhan/Urdu-Sentiment-Corpus/blob/master/urdu-sentiment-corpus-v1.tsv\n",
    "\n",
    "Implement following sequence based deep learning models for the same task of sentiment\n",
    "analysis. Perform binary text classification.\n",
    "\n",
    "\n",
    "RNN\n",
    "GRU\n",
    "LSTM\n",
    "BiLSTM\n",
    "\n",
    "You can implement these models in Keras or Pytorch. Split the data into train and test set. Use\n",
    "75% for training and 25% for testing.\n",
    "\n",
    "For each of these models, try following hyper parameters and report the best results with\n",
    "parameter values.\n",
    "Number of layers = 2 or 3.\n",
    "Dropout rate, 0.3 or 0.7\n",
    "So you will have 2 *2 = 4 different sets of parameters.\n",
    "\n",
    "Calculate accuracy, Precision, Recall and F-score for all classifiers and report the results in table.\n",
    "Also report parameter values which were used to get the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ٹویٹر کا خیال کیسے آیا ؟</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Tweet Class\n",
       "0  میں نے ایٹم بم بنایا ھے ۔۔۔۔او بھائی ایٹم بمب ...     P\n",
       "1  چندے سے انقلاب اور عمران خان وزیر اعظم نہیں بن...     N\n",
       "2                           ٹویٹر کا خیال کیسے آیا ؟     O\n",
       "3  سرچ انجن گوگل کے نائب صدر نے فضا میں ، 130,000...     P\n",
       "4    ابھی تک اسکی لہریں کبھی کبھی آ جاتی ہیں یار :أْ     P"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Load the data\n",
    "url = 'https://raw.githubusercontent.com/MuhammadYaseenKhan/Urdu-Sentiment-Corpus/master/urdu-sentiment-corpus-v1.tsv'\n",
    "# stop_words = 'https://raw.githubusercontent.com/Delta-Sigma/urdu-stopwords/master/urdu_stopwords.txt'\n",
    "# # load in stopwords\n",
    "# stop_words = np.loadtxt(stop_words, dtype='str',encoding='utf-8')\n",
    "\n",
    "df = pd.read_csv(url, delimiter='\\t',encoding='utf-8')\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words_utf8 = stop_words.astype(str)\n",
    "# stop_words_list = stop_words_utf8.tolist()\n",
    "# stop_words_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14290295583784140550\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3710910464\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 7345258031397774955\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# get gpu context\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "# model fit example for nvidia gpu\n",
    "# import tensorflow as tf\n",
    "# with tf.device('/gpu:0'):\n",
    "#     model.fit(X_train, y_train, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df.rename(columns={'Tweet': 'text', 'Class': 'label'}, inplace=True)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X = df[\"text\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "max_words = 10000\n",
    "max_len = 100\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "data = pad_sequences(tokenizer.texts_to_sequences(X), maxlen=max_len)\n",
    "labels = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# Ensure labels are integers\n",
    "# labels is a dataframe\n",
    "labels = labels.astype(int)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 100)\n",
      "(200, 100)\n",
      "(800,)\n",
      "(200,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n",
      "int32\n",
      "int32\n",
      "int32\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtype)\n",
    "print(X_test.dtype)\n",
    "print(y_train.dtype)\n",
    "print(y_test.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout, Activation, Input, LSTM, GRU, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 100)          1000000   \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 100, 128)          29312     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100, 128)          0         \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 100, 128)          32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100, 128)          0         \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,062,337\n",
      "Trainable params: 1,062,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 3s 137ms/step - loss: 0.2637 - accuracy: 0.0688 - val_loss: -0.1269 - val_accuracy: 0.0150\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 1s 96ms/step - loss: 0.2153 - accuracy: 0.0213 - val_loss: -0.1933 - val_accuracy: 0.0150\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 1s 97ms/step - loss: 0.2186 - accuracy: 0.0213 - val_loss: -0.1912 - val_accuracy: 0.0150\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 1s 98ms/step - loss: 0.1910 - accuracy: 0.0213 - val_loss: -0.0710 - val_accuracy: 0.0150\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 2s 118ms/step - loss: 0.1962 - accuracy: 0.0213 - val_loss: -0.1642 - val_accuracy: 0.0150\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 0.2075 - accuracy: 0.0213 - val_loss: -0.2586 - val_accuracy: 0.0150\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.1976 - accuracy: 0.0213 - val_loss: -0.0640 - val_accuracy: 0.0150\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.2063 - accuracy: 0.0213 - val_loss: -0.0565 - val_accuracy: 0.0150\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 0.1892 - accuracy: 0.0213 - val_loss: -0.1471 - val_accuracy: 0.0150\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.1868 - accuracy: 0.0213 - val_loss: -0.1338 - val_accuracy: 0.0150\n",
      "7/7 [==============================] - 0s 15ms/step - loss: -0.1338 - accuracy: 0.0150\n",
      "Scorer: -0.133848175406456\n",
      "Accuracy: 0.014999999664723873\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 100, 100)          1000000   \n",
      "                                                                 \n",
      " simple_rnn_2 (SimpleRNN)    (None, 100, 128)          29312     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 100, 128)          0         \n",
      "                                                                 \n",
      " simple_rnn_3 (SimpleRNN)    (None, 100, 128)          32896     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100, 128)          0         \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,062,337\n",
      "Trainable params: 1,062,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 3s 135ms/step - loss: 0.7063 - accuracy: 0.1025 - val_loss: 0.0582 - val_accuracy: 0.0150\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.2110 - accuracy: 0.0213 - val_loss: 0.0487 - val_accuracy: 0.0150\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.2641 - accuracy: 0.0288 - val_loss: -0.0060 - val_accuracy: 0.0150\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.2731 - accuracy: 0.0213 - val_loss: 0.1100 - val_accuracy: 0.0150\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.2085 - accuracy: 0.0213 - val_loss: 0.2794 - val_accuracy: 0.0150\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 1s 101ms/step - loss: 0.1986 - accuracy: 0.0213 - val_loss: 0.2575 - val_accuracy: 0.0150\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 1s 102ms/step - loss: 0.2372 - accuracy: 0.0200 - val_loss: 0.1883 - val_accuracy: 0.0150\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.2246 - accuracy: 0.0213 - val_loss: 0.1049 - val_accuracy: 0.0150\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.2215 - accuracy: 0.0213 - val_loss: 0.1288 - val_accuracy: 0.0150\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.2169 - accuracy: 0.0213 - val_loss: 0.0708 - val_accuracy: 0.0150\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0708 - accuracy: 0.0150\n",
      "Scorer: 0.07079217582941055\n",
      "Accuracy: 0.014999999664723873\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 100, 100)          1000000   \n",
      "                                                                 \n",
      " simple_rnn_4 (SimpleRNN)    (None, 100, 128)          29312     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 100, 128)          0         \n",
      "                                                                 \n",
      " simple_rnn_5 (SimpleRNN)    (None, 100, 128)          32896     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 100, 128)          0         \n",
      "                                                                 \n",
      " simple_rnn_6 (SimpleRNN)    (None, 100, 128)          32896     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 100, 128)          0         \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,095,233\n",
      "Trainable params: 1,095,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 3s 176ms/step - loss: 0.2170 - accuracy: 0.0213 - val_loss: -0.0445 - val_accuracy: 0.0150\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 2s 160ms/step - loss: 0.1984 - accuracy: 0.0213 - val_loss: -0.0621 - val_accuracy: 0.0150\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 2s 161ms/step - loss: 0.2010 - accuracy: 0.0213 - val_loss: -0.1385 - val_accuracy: 0.0150\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 2s 184ms/step - loss: 0.1961 - accuracy: 0.0213 - val_loss: -0.0599 - val_accuracy: 0.0150\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 2s 161ms/step - loss: 0.2103 - accuracy: 0.0213 - val_loss: -0.1129 - val_accuracy: 0.0150\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 2s 157ms/step - loss: 0.2095 - accuracy: 0.0213 - val_loss: -0.2128 - val_accuracy: 0.0150\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 2s 158ms/step - loss: 0.1986 - accuracy: 0.0213 - val_loss: -0.1231 - val_accuracy: 0.0150\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 2s 181ms/step - loss: 0.2068 - accuracy: 0.0213 - val_loss: -0.2494 - val_accuracy: 0.0150\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 3s 199ms/step - loss: 0.1942 - accuracy: 0.0213 - val_loss: -0.1494 - val_accuracy: 0.0150\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 3s 206ms/step - loss: 0.1916 - accuracy: 0.0213 - val_loss: -0.2123 - val_accuracy: 0.0150\n",
      "7/7 [==============================] - 0s 28ms/step - loss: -0.2123 - accuracy: 0.0150\n",
      "Scorer: -0.2123427838087082\n",
      "Accuracy: 0.014999999664723873\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 100, 100)          1000000   \n",
      "                                                                 \n",
      " simple_rnn_7 (SimpleRNN)    (None, 100, 128)          29312     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 100, 128)          0         \n",
      "                                                                 \n",
      " simple_rnn_8 (SimpleRNN)    (None, 100, 128)          32896     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 100, 128)          0         \n",
      "                                                                 \n",
      " simple_rnn_9 (SimpleRNN)    (None, 100, 128)          32896     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 100, 128)          0         \n",
      "                                                                 \n",
      " global_max_pooling1d_3 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,095,233\n",
      "Trainable params: 1,095,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 4s 229ms/step - loss: 0.2540 - accuracy: 0.0213 - val_loss: 0.2036 - val_accuracy: 0.0150\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 3s 207ms/step - loss: 0.1890 - accuracy: 0.0213 - val_loss: 0.2900 - val_accuracy: 0.0150\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 3s 208ms/step - loss: 0.2016 - accuracy: 0.0213 - val_loss: 0.3058 - val_accuracy: 0.0150\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 3s 206ms/step - loss: 0.1877 - accuracy: 0.0213 - val_loss: 0.1040 - val_accuracy: 0.0150\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 3s 203ms/step - loss: 0.1991 - accuracy: 0.0213 - val_loss: 0.0677 - val_accuracy: 0.0150\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 3s 202ms/step - loss: 0.1974 - accuracy: 0.0213 - val_loss: 0.1092 - val_accuracy: 0.0150\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 3s 207ms/step - loss: 0.1985 - accuracy: 0.0213 - val_loss: -0.0459 - val_accuracy: 0.0150\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 3s 205ms/step - loss: 0.1884 - accuracy: 0.0213 - val_loss: 0.0605 - val_accuracy: 0.0150\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 3s 206ms/step - loss: 0.1806 - accuracy: 0.0213 - val_loss: 0.0483 - val_accuracy: 0.0150\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 3s 216ms/step - loss: 0.2019 - accuracy: 0.0213 - val_loss: 0.0463 - val_accuracy: 0.0150\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.0463 - accuracy: 0.0150\n",
      "Scorer: 0.04630206152796745\n",
      "Accuracy: 0.014999999664723873\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 100, 100)          1000000   \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 100, 128)          117248    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 100, 128)          0         \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 100, 128)          131584    \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 100, 128)          0         \n",
      "                                                                 \n",
      " global_max_pooling1d_4 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,248,961\n",
      "Trainable params: 1,248,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 3s 63ms/step - loss: 0.3056 - accuracy: 0.0575 - val_loss: -0.3102 - val_accuracy: 0.0150\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2636 - accuracy: 0.0213 - val_loss: -0.2170 - val_accuracy: 0.0150\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 0.2170 - accuracy: 0.0213 - val_loss: -0.0671 - val_accuracy: 0.0150\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.1849 - accuracy: 0.0213 - val_loss: -0.0174 - val_accuracy: 0.0150\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.1848 - accuracy: 0.0213 - val_loss: -0.0026 - val_accuracy: 0.0150\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.1852 - accuracy: 0.0213 - val_loss: 5.2822e-04 - val_accuracy: 0.0150\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.1891 - accuracy: 0.0213 - val_loss: 0.0242 - val_accuracy: 0.0150\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.1868 - accuracy: 0.0213 - val_loss: -0.0285 - val_accuracy: 0.0150\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.1884 - accuracy: 0.0213 - val_loss: -0.0319 - val_accuracy: 0.0150\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.1868 - accuracy: 0.0213 - val_loss: -0.0182 - val_accuracy: 0.0150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: -0.0182 - accuracy: 0.0150\n",
      "Scorer: -0.018247928470373154\n",
      "Accuracy: 0.014999999664723873\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_5 (Embedding)     (None, 100, 100)          1000000   \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 100, 128)          117248    \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 100, 128)          0         \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 100, 128)          131584    \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 100, 128)          0         \n",
      "                                                                 \n",
      " global_max_pooling1d_5 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,248,961\n",
      "Trainable params: 1,248,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 2s 56ms/step - loss: 0.4329 - accuracy: 0.0213 - val_loss: 0.2399 - val_accuracy: 0.0150\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 18ms/step - loss: 0.2120 - accuracy: 0.0213 - val_loss: 0.3697 - val_accuracy: 0.0150\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.2329 - accuracy: 0.0213 - val_loss: 0.1834 - val_accuracy: 0.0150\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.2399 - accuracy: 0.0213 - val_loss: 0.3951 - val_accuracy: 0.0150\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.1941 - accuracy: 0.0213 - val_loss: 0.2143 - val_accuracy: 0.0150\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.2189 - accuracy: 0.0213 - val_loss: 0.2674 - val_accuracy: 0.0150\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.1910 - accuracy: 0.0213 - val_loss: 0.2937 - val_accuracy: 0.0150\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.1866 - accuracy: 0.0213 - val_loss: 0.3007 - val_accuracy: 0.0150\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.2117 - accuracy: 0.0213 - val_loss: 0.3513 - val_accuracy: 0.0150\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 15ms/step - loss: 0.1859 - accuracy: 0.0213 - val_loss: 0.2688 - val_accuracy: 0.0150\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2688 - accuracy: 0.0150\n",
      "Scorer: 0.26877108216285706\n",
      "Accuracy: 0.014999999664723873\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, 100, 100)          1000000   \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 100, 128)          117248    \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 100, 128)          0         \n",
      "                                                                 \n",
      " lstm_12 (LSTM)              (None, 100, 128)          131584    \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 100, 128)          0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 100, 128)          131584    \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 100, 128)          0         \n",
      "                                                                 \n",
      " global_max_pooling1d_6 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,380,545\n",
      "Trainable params: 1,380,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 3s 85ms/step - loss: 0.4043 - accuracy: 0.0500 - val_loss: 0.0212 - val_accuracy: 0.0150\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 0.2091 - accuracy: 0.0213 - val_loss: 0.0470 - val_accuracy: 0.0150\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.1841 - accuracy: 0.0213 - val_loss: -0.0786 - val_accuracy: 0.0150\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 0.2266 - accuracy: 0.0213 - val_loss: -0.1373 - val_accuracy: 0.0150\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 0.1998 - accuracy: 0.0213 - val_loss: -0.0047 - val_accuracy: 0.0150\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 0.1874 - accuracy: 0.0213 - val_loss: -0.0304 - val_accuracy: 0.0150\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.1831 - accuracy: 0.0213 - val_loss: -0.0691 - val_accuracy: 0.0150\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.1840 - accuracy: 0.0213 - val_loss: -0.0928 - val_accuracy: 0.0150\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 0.1994 - accuracy: 0.0213 - val_loss: -0.1050 - val_accuracy: 0.0150\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 31ms/step - loss: 0.1915 - accuracy: 0.0213 - val_loss: -0.0078 - val_accuracy: 0.0150\n",
      "7/7 [==============================] - 0s 14ms/step - loss: -0.0078 - accuracy: 0.0150\n",
      "Scorer: -0.007805377244949341\n",
      "Accuracy: 0.014999999664723873\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 100, 100)          1000000   \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 100, 128)          117248    \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 100, 128)          0         \n",
      "                                                                 \n",
      " lstm_16 (LSTM)              (None, 100, 128)          131584    \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 100, 128)          0         \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 100, 128)          131584    \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 100, 128)          0         \n",
      "                                                                 \n",
      " global_max_pooling1d_7 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,380,545\n",
      "Trainable params: 1,380,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 4s 98ms/step - loss: 0.2774 - accuracy: 0.0550 - val_loss: 0.1755 - val_accuracy: 0.0150\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 0.2444 - accuracy: 0.0213 - val_loss: 0.2711 - val_accuracy: 0.0150\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 33ms/step - loss: 0.1863 - accuracy: 0.0213 - val_loss: 0.3502 - val_accuracy: 0.0150\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 0.1951 - accuracy: 0.0213 - val_loss: 0.3003 - val_accuracy: 0.0150\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 0.2059 - accuracy: 0.0213 - val_loss: 0.2680 - val_accuracy: 0.0150\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.2079 - accuracy: 0.0213 - val_loss: 0.2664 - val_accuracy: 0.0150\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 35ms/step - loss: 0.1908 - accuracy: 0.0213 - val_loss: 0.2377 - val_accuracy: 0.0150\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.1924 - accuracy: 0.0213 - val_loss: 0.3168 - val_accuracy: 0.0150\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 0.2183 - accuracy: 0.0213 - val_loss: 0.3070 - val_accuracy: 0.0150\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 34ms/step - loss: 0.2028 - accuracy: 0.0213 - val_loss: 0.3285 - val_accuracy: 0.0150\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.3285 - accuracy: 0.0150\n",
      "Scorer: 0.32848697900772095\n",
      "Accuracy: 0.014999999664723873\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 100, 100)          1000000   \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 100, 128)          88320     \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 100, 128)          0         \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (None, 100, 128)          99072     \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 100, 128)          0         \n",
      "                                                                 \n",
      " global_max_pooling1d_8 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,187,521\n",
      "Trainable params: 1,187,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 3s 63ms/step - loss: 0.4225 - accuracy: 0.0213 - val_loss: -0.1425 - val_accuracy: 0.0150\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.2282 - accuracy: 0.0213 - val_loss: 0.0580 - val_accuracy: 0.0150\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 0.2109 - accuracy: 0.0213 - val_loss: -0.1082 - val_accuracy: 0.0150\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.2054 - accuracy: 0.0213 - val_loss: -0.0477 - val_accuracy: 0.0150\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.1978 - accuracy: 0.0213 - val_loss: 0.0750 - val_accuracy: 0.0150\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.2002 - accuracy: 0.0213 - val_loss: -0.0222 - val_accuracy: 0.0150\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.1803 - accuracy: 0.0213 - val_loss: -0.1025 - val_accuracy: 0.0150\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.1878 - accuracy: 0.0213 - val_loss: -0.0813 - val_accuracy: 0.0150\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.1909 - accuracy: 0.0213 - val_loss: -0.0635 - val_accuracy: 0.0150\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.1992 - accuracy: 0.0213 - val_loss: -0.0709 - val_accuracy: 0.0150\n",
      "7/7 [==============================] - 0s 9ms/step - loss: -0.0709 - accuracy: 0.0150\n",
      "Scorer: -0.07087110728025436\n",
      "Accuracy: 0.014999999664723873\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_9 (Embedding)     (None, 100, 100)          1000000   \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (None, 100, 128)          88320     \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 100, 128)          0         \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 100, 128)          99072     \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 100, 128)          0         \n",
      "                                                                 \n",
      " global_max_pooling1d_9 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,187,521\n",
      "Trainable params: 1,187,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 3s 58ms/step - loss: 0.4471 - accuracy: 0.0688 - val_loss: 0.2201 - val_accuracy: 0.0150\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 29ms/step - loss: 0.2714 - accuracy: 0.0213 - val_loss: 0.4773 - val_accuracy: 0.0150\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.2022 - accuracy: 0.0213 - val_loss: 0.3586 - val_accuracy: 0.0150\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.2043 - accuracy: 0.0213 - val_loss: 0.3360 - val_accuracy: 0.0150\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.1881 - accuracy: 0.0213 - val_loss: 0.3673 - val_accuracy: 0.0150\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 25ms/step - loss: 0.1930 - accuracy: 0.0213 - val_loss: 0.3507 - val_accuracy: 0.0150\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 26ms/step - loss: 0.2008 - accuracy: 0.0213 - val_loss: 0.3951 - val_accuracy: 0.0150\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 24ms/step - loss: 0.1832 - accuracy: 0.0213 - val_loss: 0.2959 - val_accuracy: 0.0150\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 28ms/step - loss: 0.2574 - accuracy: 0.0213 - val_loss: 0.2753 - val_accuracy: 0.0150\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 23ms/step - loss: 0.2038 - accuracy: 0.0213 - val_loss: 0.4395 - val_accuracy: 0.0150\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.4395 - accuracy: 0.0150\n",
      "Scorer: 0.43952345848083496\n",
      "Accuracy: 0.014999999664723873\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_10 (Embedding)    (None, 100, 100)          1000000   \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, 100, 128)          88320     \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 100, 128)          0         \n",
      "                                                                 \n",
      " gru_5 (GRU)                 (None, 100, 128)          99072     \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 100, 128)          0         \n",
      "                                                                 \n",
      " gru_6 (GRU)                 (None, 100, 128)          99072     \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 100, 128)          0         \n",
      "                                                                 \n",
      " global_max_pooling1d_10 (Gl  (None, 128)              0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,286,593\n",
      "Trainable params: 1,286,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 3s 86ms/step - loss: 0.3702 - accuracy: 0.0213 - val_loss: -0.1399 - val_accuracy: 0.0150\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 32ms/step - loss: 0.2471 - accuracy: 0.0213 - val_loss: 0.1536 - val_accuracy: 0.0150\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 36ms/step - loss: 0.1998 - accuracy: 0.0213 - val_loss: -0.1427 - val_accuracy: 0.0150\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2018 - accuracy: 0.0213 - val_loss: -0.0130 - val_accuracy: 0.0150\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.1965 - accuracy: 0.0213 - val_loss: 0.0859 - val_accuracy: 0.0150\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 19ms/step - loss: 0.1888 - accuracy: 0.0213 - val_loss: -0.0363 - val_accuracy: 0.0150\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.2126 - accuracy: 0.0213 - val_loss: -0.0174 - val_accuracy: 0.0150\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1915 - accuracy: 0.0213 - val_loss: -0.0109 - val_accuracy: 0.0150\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.2534 - accuracy: 0.0213 - val_loss: -0.1562 - val_accuracy: 0.0150\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.2201 - accuracy: 0.0213 - val_loss: 0.1041 - val_accuracy: 0.0150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1041 - accuracy: 0.0150 \n",
      "Scorer: 0.10410602390766144\n",
      "Accuracy: 0.014999999664723873\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_11 (Embedding)    (None, 100, 100)          1000000   \n",
      "                                                                 \n",
      " gru_7 (GRU)                 (None, 100, 128)          88320     \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 100, 128)          0         \n",
      "                                                                 \n",
      " gru_8 (GRU)                 (None, 100, 128)          99072     \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 100, 128)          0         \n",
      "                                                                 \n",
      " gru_9 (GRU)                 (None, 100, 128)          99072     \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 100, 128)          0         \n",
      "                                                                 \n",
      " global_max_pooling1d_11 (Gl  (None, 128)              0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,286,593\n",
      "Trainable params: 1,286,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "13/13 [==============================] - 3s 71ms/step - loss: 0.4343 - accuracy: 0.0213 - val_loss: 0.3482 - val_accuracy: 0.0150\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.2004 - accuracy: 0.0213 - val_loss: 0.5047 - val_accuracy: 0.0150\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.1968 - accuracy: 0.0213 - val_loss: 0.3531 - val_accuracy: 0.0150\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.2048 - accuracy: 0.0213 - val_loss: 0.3455 - val_accuracy: 0.0150\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.1895 - accuracy: 0.0213 - val_loss: 0.4186 - val_accuracy: 0.0150\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.1959 - accuracy: 0.0213 - val_loss: 0.4430 - val_accuracy: 0.0150\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.1973 - accuracy: 0.0213 - val_loss: 0.3635 - val_accuracy: 0.0150\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.1884 - accuracy: 0.0213 - val_loss: 0.4159 - val_accuracy: 0.0150\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.1995 - accuracy: 0.0213 - val_loss: 0.3874 - val_accuracy: 0.0150\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 22ms/step - loss: 0.1945 - accuracy: 0.0213 - val_loss: 0.4060 - val_accuracy: 0.0150\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4060 - accuracy: 0.0150\n",
      "Scorer: 0.40595895051956177\n",
      "Accuracy: 0.014999999664723873\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"bidirectional\" is incompatible with the layer: expected ndim=3, found ndim=0. Full shape received: ()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Embedding(input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, output_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, input_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m))\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(hyperparameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m]):\n\u001b[1;32m---> 28\u001b[0m     model\u001b[38;5;241m.\u001b[39madd(\u001b[43mmodels\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[0;32m     29\u001b[0m     model\u001b[38;5;241m.\u001b[39madd(Dropout(hyperparameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[0;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39madd(GlobalMaxPooling1D())  \u001b[38;5;66;03m# This will convert the output shape from (None, 100, 64) to (None, 64)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ammar\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\layers\\rnn\\bidirectional.py:277\u001b[0m, in \u001b[0;36mBidirectional.__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    274\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m initial_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m constants \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    279\u001b[0m \u001b[38;5;66;03m# Applies the same workaround as in `RNN.__call__`\u001b[39;00m\n\u001b[0;32m    280\u001b[0m additional_inputs \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\ammar\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\ammar\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\input_spec.py:232\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    230\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m shape\u001b[38;5;241m.\u001b[39mrank\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;241m!=\u001b[39m spec\u001b[38;5;241m.\u001b[39mndim:\n\u001b[1;32m--> 232\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    233\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    234\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis incompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    235\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, found ndim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    236\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFull shape received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(shape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    237\u001b[0m         )\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec\u001b[38;5;241m.\u001b[39mmax_ndim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    239\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"bidirectional\" is incompatible with the layer: expected ndim=3, found ndim=0. Full shape received: ()"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
    "\n",
    "hyperparameter_combinations = [\n",
    "    # comb 1\n",
    "    {\"num_layers\": 2, \"dropout_rate\": 0.3},\n",
    "    \n",
    "    # comb 2\n",
    "    {\"num_layers\": 2, \"dropout_rate\": 0.7},\n",
    "    \n",
    "    # comb 3\n",
    "    {\"num_layers\": 3, \"dropout_rate\": 0.3},\n",
    "    \n",
    "    # comb 4\n",
    "    {\"num_layers\": 3, \"dropout_rate\": 0.7}\n",
    "]\n",
    "\n",
    "models = [SimpleRNN, LSTM, GRU, Bidirectional(LSTM(units=64, return_sequences=True))]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for models in models:\n",
    "    for hyperparameters in hyperparameter_combinations:\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(input_dim=10000, output_dim=100, input_length=100))\n",
    "        for i in range(hyperparameters[\"num_layers\"]):\n",
    "            model.add(models(128, return_sequences=True))\n",
    "            model.add(Dropout(hyperparameters[\"dropout_rate\"]))\n",
    "        model.add(GlobalMaxPooling1D())  # This will convert the output shape from (None, 100, 64) to (None, 64)\n",
    "        model.add(Dense(1, activation=\"sigmoid\"))\n",
    "        model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "        model.summary()\n",
    "        \n",
    "        if models == Bidirectional(LSTM(units=64, return_sequences=True)):\n",
    "            epoch   = 10\n",
    "            batch   = 32\n",
    "            model.fit(X_train, y_train, epochs=epoch, batch_size=batch, validation_data=(X_test, y_test))\n",
    "            \n",
    "        # X_train_pad = pad_sequences(X_train, maxlen=100, padding=\"post\")\n",
    "        # X_test_pad = pad_sequences(X_test, maxlen=100, padding=\"post\")\n",
    "        \n",
    "        with tf.device('/gpu:0'):\n",
    "            model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n",
    "        \n",
    "        # Make predictions\n",
    "        scorer, acc = model.evaluate(X_test, y_test)\n",
    "        # Calculate the classification report\n",
    "        print('Scorer:', scorer)\n",
    "        print('Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This question uses same dataset of Q 1. Perform the task of binary classification on the dataset.\n",
    "Choose one classifier from deep learning models implemented in Question 1 based on best\n",
    "results on F-measure for binary classification.\n",
    "Use following embedding for vector representation and report the results. You need to train\n",
    "the embeddings yourself on the given Urdu dataset.\n",
    "1) WordToVec\n",
    "\n",
    "https://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/\n",
    "2) Glove\n",
    "https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "https://medium.com/analytics-vidhya/basics-of-using-pre-trained-glove-vectors-in-\n",
    "python-d38905f356db\n",
    "\n",
    "3) Fasttext\n",
    "\n",
    "https://blogs.sap.com/2019/07/03/glove-and-fasttext-two-popular-word-vector-\n",
    "models-in-nlp/\n",
    "\n",
    "https://fasttext.cc/docs/en/english-vectors.html\n",
    "4) Elmo (it creates embeddings for sentences, so use entire tweet as imput to get the\n",
    "vector) https://github.com/HIT-SCIR/ELMoForManyLangs\n",
    "\n",
    "Calculate accuracy, Precision, Recall and F-score for all classifiers and report the results in\n",
    "tables. For example, if LSTM (use any fixed hyper-parameters that gave best results) had best\n",
    "overall results among deep learning models in your assignment 1 then make the following table\n",
    "of results.\n",
    "\n",
    "LSTM\n",
    "(without\n",
    "embeddings)\n",
    "\n",
    "LSTM with\n",
    "WordToVec\n",
    "\n",
    "LSTM with\n",
    "Glove\n",
    "\n",
    "LSTM with\n",
    "Fasttext\n",
    "\n",
    "LSTM with\n",
    "Elmo\n",
    "\n",
    "F-score\n",
    "Accuracy\n",
    "Precision\n",
    "Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pybind11 in c:\\users\\ammar\\anaconda3\\lib\\site-packages (2.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --use-pep517 pybind11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\ammar\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\ammar\\anaconda3\\lib\\site-packages (from gensim) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\ammar\\anaconda3\\lib\\site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\ammar\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: FuzzyTM>=0.4.0 in c:\\users\\ammar\\anaconda3\\lib\\site-packages (from gensim) (2.0.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\ammar\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (2.1.4)\n",
      "Requirement already satisfied: pyfume in c:\\users\\ammar\\anaconda3\\lib\\site-packages (from FuzzyTM>=0.4.0->gensim) (0.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ammar\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ammar\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\ammar\\anaconda3\\lib\\site-packages (from pandas->FuzzyTM>=0.4.0->gensim) (2023.3)\n",
      "Requirement already satisfied: simpful in c:\\users\\ammar\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (2.12.0)\n",
      "Requirement already satisfied: fst-pso in c:\\users\\ammar\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (1.8.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ammar\\anaconda3\\lib\\site-packages (from pyfume->FuzzyTM>=0.4.0->gensim) (4.9.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ammar\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->FuzzyTM>=0.4.0->gensim) (1.16.0)\n",
      "Requirement already satisfied: miniful in c:\\users\\ammar\\anaconda3\\lib\\site-packages (from fst-pso->pyfume->FuzzyTM>=0.4.0->gensim) (0.0.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fasttext\n",
      "  Using cached fasttext-0.9.2.tar.gz (68 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Getting requirements to build wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [28 lines of output]\n",
      "      c:\\Users\\ammar\\anaconda3\\python.exe: No module named pip\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 38, in __init__\n",
      "      ModuleNotFoundError: No module named 'pybind11'\n",
      "      \n",
      "      During handling of the above exception, another exception occurred:\n",
      "      \n",
      "      Traceback (most recent call last):\n",
      "        File \"c:\\Users\\ammar\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "        File \"c:\\Users\\ammar\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"c:\\Users\\ammar\\anaconda3\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "          return hook(config_settings)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\ammar\\AppData\\Local\\Temp\\pip-build-env-gjbla9p5\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 325, in get_requires_for_build_wheel\n",
      "          return self._get_build_requires(config_settings, requirements=['wheel'])\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\ammar\\AppData\\Local\\Temp\\pip-build-env-gjbla9p5\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 295, in _get_build_requires\n",
      "          self.run_setup()\n",
      "        File \"C:\\Users\\ammar\\AppData\\Local\\Temp\\pip-build-env-gjbla9p5\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 487, in run_setup\n",
      "          super().run_setup(setup_script=setup_script)\n",
      "        File \"C:\\Users\\ammar\\AppData\\Local\\Temp\\pip-build-env-gjbla9p5\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 311, in run_setup\n",
      "          exec(code, locals())\n",
      "        File \"<string>\", line 72, in <module>\n",
      "        File \"<string>\", line 41, in __init__\n",
      "      RuntimeError: pybind11 install failed.\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× Getting requirements to build wheel did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install --use-pep517 fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × pip subprocess to install build dependencies did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [339 lines of output]\n",
      "      Collecting setuptools\n",
      "        Using cached setuptools-69.2.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "      Collecting wheel<0.33.0,>0.32.0\n",
      "        Using cached wheel-0.32.3-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "      Collecting Cython\n",
      "        Using cached Cython-3.0.10-cp311-cp311-win_amd64.whl.metadata (3.2 kB)\n",
      "      Collecting cymem<2.1.0,>=2.0.2\n",
      "        Using cached cymem-2.0.8-cp311-cp311-win_amd64.whl.metadata (8.6 kB)\n",
      "      Collecting preshed<2.1.0,>=2.0.1\n",
      "        Using cached preshed-2.0.1.tar.gz (113 kB)\n",
      "        Preparing metadata (setup.py): started\n",
      "        Preparing metadata (setup.py): finished with status 'done'\n",
      "      Collecting murmurhash<1.1.0,>=0.28.0\n",
      "        Using cached murmurhash-1.0.10-cp311-cp311-win_amd64.whl.metadata (2.0 kB)\n",
      "      Collecting thinc<7.1.0,>=7.0.8\n",
      "        Using cached thinc-7.0.8.tar.gz (1.9 MB)\n",
      "        Preparing metadata (setup.py): started\n",
      "        Preparing metadata (setup.py): finished with status 'done'\n",
      "      Collecting blis<0.3.0,>=0.2.1 (from thinc<7.1.0,>=7.0.8)\n",
      "        Using cached blis-0.2.4.tar.gz (1.5 MB)\n",
      "        Preparing metadata (setup.py): started\n",
      "        Preparing metadata (setup.py): finished with status 'done'\n",
      "      Collecting wasabi<1.1.0,>=0.0.9 (from thinc<7.1.0,>=7.0.8)\n",
      "        Using cached wasabi-0.10.1-py3-none-any.whl.metadata (28 kB)\n",
      "      Collecting srsly<1.1.0,>=0.0.6 (from thinc<7.1.0,>=7.0.8)\n",
      "        Using cached srsly-1.0.7-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "      Collecting numpy>=1.7.0 (from thinc<7.1.0,>=7.0.8)\n",
      "        Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "      Collecting plac<1.0.0,>=0.9.6 (from thinc<7.1.0,>=7.0.8)\n",
      "        Using cached plac-0.9.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "      Collecting tqdm<5.0.0,>=4.10.0 (from thinc<7.1.0,>=7.0.8)\n",
      "        Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "      Collecting colorama (from tqdm<5.0.0,>=4.10.0->thinc<7.1.0,>=7.0.8)\n",
      "        Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "      Using cached setuptools-69.2.0-py3-none-any.whl (821 kB)\n",
      "      Using cached wheel-0.32.3-py2.py3-none-any.whl (21 kB)\n",
      "      Using cached Cython-3.0.10-cp311-cp311-win_amd64.whl (2.8 MB)\n",
      "      Using cached cymem-2.0.8-cp311-cp311-win_amd64.whl (39 kB)\n",
      "      Using cached murmurhash-1.0.10-cp311-cp311-win_amd64.whl (25 kB)\n",
      "      Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "      Using cached plac-0.9.6-py2.py3-none-any.whl (20 kB)\n",
      "      Using cached srsly-1.0.7-cp311-cp311-win_amd64.whl (354 kB)\n",
      "      Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "      Using cached wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
      "      Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "      Building wheels for collected packages: preshed, thinc, blis\n",
      "        Building wheel for preshed (setup.py): started\n",
      "        Building wheel for preshed (setup.py): finished with status 'error'\n",
      "        error: subprocess-exited-with-error\n",
      "      \n",
      "        Ã— python setup.py bdist_wheel did not run successfully.\n",
      "        â”‚ exit code: 1\n",
      "        â•°â”€> [37 lines of output]\n",
      "            c:\\Users\\ammar\\anaconda3\\Lib\\site-packages\\setuptools\\__init__.py:80: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "            !!\n",
      "      \n",
      "                    ********************************************************************************\n",
      "                    Requirements should be satisfied by a PEP 517 installer.\n",
      "                    If you are using pip, you can try `pip install --use-pep517`.\n",
      "                    ********************************************************************************\n",
      "      \n",
      "            !!\n",
      "              dist.fetch_build_eggs(dist.setup_requires)\n",
      "            running bdist_wheel\n",
      "            running build\n",
      "            running build_py\n",
      "            creating build\n",
      "            creating build\\lib.win-amd64-cpython-311\n",
      "            creating build\\lib.win-amd64-cpython-311\\preshed\n",
      "            copying preshed\\about.py -> build\\lib.win-amd64-cpython-311\\preshed\n",
      "            copying preshed\\__init__.py -> build\\lib.win-amd64-cpython-311\\preshed\n",
      "            creating build\\lib.win-amd64-cpython-311\\preshed\\tests\n",
      "            copying preshed\\tests\\test_counter.py -> build\\lib.win-amd64-cpython-311\\preshed\\tests\n",
      "            copying preshed\\tests\\test_hashing.py -> build\\lib.win-amd64-cpython-311\\preshed\\tests\n",
      "            copying preshed\\tests\\test_pop.py -> build\\lib.win-amd64-cpython-311\\preshed\\tests\n",
      "            copying preshed\\tests\\__init__.py -> build\\lib.win-amd64-cpython-311\\preshed\\tests\n",
      "            copying preshed\\counter.pyx -> build\\lib.win-amd64-cpython-311\\preshed\n",
      "            copying preshed\\maps.pyx -> build\\lib.win-amd64-cpython-311\\preshed\n",
      "            copying preshed\\counter.pxd -> build\\lib.win-amd64-cpython-311\\preshed\n",
      "            copying preshed\\maps.pxd -> build\\lib.win-amd64-cpython-311\\preshed\n",
      "            copying preshed\\__init__.pxd -> build\\lib.win-amd64-cpython-311\\preshed\n",
      "            running build_ext\n",
      "            building 'preshed.maps' extension\n",
      "            creating build\\temp.win-amd64-cpython-311\n",
      "            creating build\\temp.win-amd64-cpython-311\\Release\n",
      "            creating build\\temp.win-amd64-cpython-311\\Release\\preshed\n",
      "            \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.39.33519\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -Ic:\\Users\\ammar\\anaconda3\\include -Ic:\\Users\\ammar\\anaconda3\\include -Ic:\\Users\\ammar\\anaconda3\\Include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.39.33519\\include\" \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Auxiliary\\VS\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22621.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\cppwinrt\" /EHsc /Tppreshed/maps.cpp /Fobuild\\temp.win-amd64-cpython-311\\Release\\preshed/maps.obj /Ox /EHsc\n",
      "            maps.cpp\n",
      "            preshed/maps.cpp(181): fatal error C1083: Cannot open include file: 'longintrepr.h': No such file or directory\n",
      "            error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2022\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.39.33519\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
      "            [end of output]\n",
      "      \n",
      "        note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "        ERROR: Failed building wheel for preshed\n",
      "        Running setup.py clean for preshed\n",
      "        Building wheel for thinc (setup.py): started\n",
      "        Building wheel for thinc (setup.py): finished with status 'error'\n",
      "        error: subprocess-exited-with-error\n",
      "      \n",
      "        Ã— python setup.py bdist_wheel did not run successfully.\n",
      "        â”‚ exit code: 1\n",
      "        â•°â”€> [183 lines of output]\n",
      "            c:\\Users\\ammar\\anaconda3\\Lib\\site-packages\\setuptools\\__init__.py:80: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "            !!\n",
      "      \n",
      "                    ********************************************************************************\n",
      "                    Requirements should be satisfied by a PEP 517 installer.\n",
      "                    If you are using pip, you can try `pip install --use-pep517`.\n",
      "                    ********************************************************************************\n",
      "      \n",
      "            !!\n",
      "              dist.fetch_build_eggs(dist.setup_requires)\n",
      "            running bdist_wheel\n",
      "            running build\n",
      "            running build_py\n",
      "            creating build\n",
      "            creating build\\lib.win-amd64-cpython-311\n",
      "            creating build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\about.py -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\api.py -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\check.py -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\compat.py -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\describe.py -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\exceptions.py -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\i2v.py -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\loss.py -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\misc.py -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\rates.py -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\t2t.py -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\t2v.py -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\v2v.py -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\__init__.py -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            creating build\\lib.win-amd64-cpython-311\\thinc\\tests\n",
      "            copying thinc\\tests\\conftest.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\n",
      "            copying thinc\\tests\\strategies.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\n",
      "            copying thinc\\tests\\test_api_funcs.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\n",
      "            copying thinc\\tests\\test_util.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\n",
      "            copying thinc\\tests\\util.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\n",
      "            copying thinc\\tests\\__init__.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\n",
      "            creating build\\lib.win-amd64-cpython-311\\thinc\\tests\\unit\n",
      "            copying thinc\\tests\\unit\\test_about.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\unit\n",
      "            copying thinc\\tests\\unit\\test_affine.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\unit\n",
      "            copying thinc\\tests\\unit\\test_beam_search.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\unit\n",
      "            copying thinc\\tests\\unit\\test_check_exceptions.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\unit\n",
      "            copying thinc\\tests\\unit\\test_difference.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\unit\n",
      "            copying thinc\\tests\\unit\\test_feature_extracter.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\unit\n",
      "            copying thinc\\tests\\unit\\test_hash_embed.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\unit\n",
      "            copying thinc\\tests\\unit\\test_imports.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\unit\n",
      "            copying thinc\\tests\\unit\\test_linear.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\unit\n",
      "            copying thinc\\tests\\unit\\test_loss.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\unit\n",
      "            copying thinc\\tests\\unit\\test_mem.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\unit\n",
      "            copying thinc\\tests\\unit\\test_model.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\unit\n",
      "            copying thinc\\tests\\unit\\test_ops.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\unit\n",
      "            copying thinc\\tests\\unit\\test_pickle.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\unit\n",
      "            copying thinc\\tests\\unit\\test_pooling.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\unit\n",
      "            copying thinc\\tests\\unit\\test_pytorch_wrapper.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\unit\n",
      "            copying thinc\\tests\\unit\\test_rates.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\unit\n",
      "            copying thinc\\tests\\unit\\test_rnn.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\unit\n",
      "            copying thinc\\tests\\unit\\__init__.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\unit\n",
      "            creating build\\lib.win-amd64-cpython-311\\thinc\\tests\\integration\n",
      "            copying thinc\\tests\\integration\\test_affine_learns.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\integration\n",
      "            copying thinc\\tests\\integration\\test_basic_tagger.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\integration\n",
      "            copying thinc\\tests\\integration\\test_batch_norm.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\integration\n",
      "            copying thinc\\tests\\integration\\test_feed_forward.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\integration\n",
      "            copying thinc\\tests\\integration\\test_mnist.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\integration\n",
      "            copying thinc\\tests\\integration\\test_pickle.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\integration\n",
      "            copying thinc\\tests\\integration\\test_roundtrip_bytes.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\integration\n",
      "            copying thinc\\tests\\integration\\test_shape_check.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\integration\n",
      "            copying thinc\\tests\\integration\\__init__.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\integration\n",
      "            creating build\\lib.win-amd64-cpython-311\\thinc\\tests\\linear\n",
      "            copying thinc\\tests\\linear\\test_avgtron.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\linear\n",
      "            copying thinc\\tests\\linear\\test_linear.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\linear\n",
      "            copying thinc\\tests\\linear\\test_sparse_array.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\linear\n",
      "            copying thinc\\tests\\linear\\__init__.py -> build\\lib.win-amd64-cpython-311\\thinc\\tests\\linear\n",
      "            creating build\\lib.win-amd64-cpython-311\\thinc\\linear\n",
      "            copying thinc\\linear\\__init__.py -> build\\lib.win-amd64-cpython-311\\thinc\\linear\n",
      "            creating build\\lib.win-amd64-cpython-311\\thinc\\neural\n",
      "            copying thinc\\neural\\mem.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\n",
      "            copying thinc\\neural\\pooling.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\n",
      "            copying thinc\\neural\\train.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\n",
      "            copying thinc\\neural\\util.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\n",
      "            copying thinc\\neural\\vec2vec.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\n",
      "            copying thinc\\neural\\vecs2vec.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\n",
      "            copying thinc\\neural\\vecs2vecs.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\n",
      "            copying thinc\\neural\\_lsuv.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\n",
      "            copying thinc\\neural\\__init__.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\n",
      "            creating build\\lib.win-amd64-cpython-311\\thinc\\extra\n",
      "            copying thinc\\extra\\datasets.py -> build\\lib.win-amd64-cpython-311\\thinc\\extra\n",
      "            copying thinc\\extra\\hpbff.py -> build\\lib.win-amd64-cpython-311\\thinc\\extra\n",
      "            copying thinc\\extra\\load_nlp.py -> build\\lib.win-amd64-cpython-311\\thinc\\extra\n",
      "            copying thinc\\extra\\visualizer.py -> build\\lib.win-amd64-cpython-311\\thinc\\extra\n",
      "            copying thinc\\extra\\wrappers.py -> build\\lib.win-amd64-cpython-311\\thinc\\extra\n",
      "            copying thinc\\extra\\__init__.py -> build\\lib.win-amd64-cpython-311\\thinc\\extra\n",
      "            creating build\\lib.win-amd64-cpython-311\\thinc\\neural\\_classes\n",
      "            copying thinc\\neural\\_classes\\affine.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\\_classes\n",
      "            copying thinc\\neural\\_classes\\attention.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\\_classes\n",
      "            copying thinc\\neural\\_classes\\batchnorm.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\\_classes\n",
      "            copying thinc\\neural\\_classes\\convolution.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\\_classes\n",
      "            copying thinc\\neural\\_classes\\difference.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\\_classes\n",
      "            copying thinc\\neural\\_classes\\elu.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\\_classes\n",
      "            copying thinc\\neural\\_classes\\embed.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\\_classes\n",
      "            copying thinc\\neural\\_classes\\encoder_decoder.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\\_classes\n",
      "            copying thinc\\neural\\_classes\\feature_extracter.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\\_classes\n",
      "            copying thinc\\neural\\_classes\\feed_forward.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\\_classes\n",
      "            copying thinc\\neural\\_classes\\function_layer.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\\_classes\n",
      "            copying thinc\\neural\\_classes\\hash_embed.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\\_classes\n",
      "            copying thinc\\neural\\_classes\\layernorm.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\\_classes\n",
      "            copying thinc\\neural\\_classes\\maxout.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\\_classes\n",
      "            copying thinc\\neural\\_classes\\model.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\\_classes\n",
      "            copying thinc\\neural\\_classes\\multiheaded_attention.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\\_classes\n",
      "            copying thinc\\neural\\_classes\\relu.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\\_classes\n",
      "            copying thinc\\neural\\_classes\\resnet.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\\_classes\n",
      "            copying thinc\\neural\\_classes\\rnn.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\\_classes\n",
      "            copying thinc\\neural\\_classes\\selu.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\\_classes\n",
      "            copying thinc\\neural\\_classes\\softmax.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\\_classes\n",
      "            copying thinc\\neural\\_classes\\static_vectors.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\\_classes\n",
      "            copying thinc\\neural\\_classes\\__init__.py -> build\\lib.win-amd64-cpython-311\\thinc\\neural\\_classes\n",
      "            creating build\\lib.win-amd64-cpython-311\\thinc\\extra\\_vendorized\n",
      "            copying thinc\\extra\\_vendorized\\keras_datasets.py -> build\\lib.win-amd64-cpython-311\\thinc\\extra\\_vendorized\n",
      "            copying thinc\\extra\\_vendorized\\keras_data_utils.py -> build\\lib.win-amd64-cpython-311\\thinc\\extra\\_vendorized\n",
      "            copying thinc\\extra\\_vendorized\\keras_generic_utils.py -> build\\lib.win-amd64-cpython-311\\thinc\\extra\\_vendorized\n",
      "            copying thinc\\extra\\_vendorized\\__init__.py -> build\\lib.win-amd64-cpython-311\\thinc\\extra\\_vendorized\n",
      "            creating build\\lib.win-amd64-cpython-311\\thinc\\extra\\wrapt\n",
      "            copying thinc\\extra\\wrapt\\decorators.py -> build\\lib.win-amd64-cpython-311\\thinc\\extra\\wrapt\n",
      "            copying thinc\\extra\\wrapt\\importer.py -> build\\lib.win-amd64-cpython-311\\thinc\\extra\\wrapt\n",
      "            copying thinc\\extra\\wrapt\\wrappers.py -> build\\lib.win-amd64-cpython-311\\thinc\\extra\\wrapt\n",
      "            copying thinc\\extra\\wrapt\\__init__.py -> build\\lib.win-amd64-cpython-311\\thinc\\extra\\wrapt\n",
      "            copying thinc\\linalg.pyx -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\structs.pyx -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\typedefs.pyx -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\cpu.pxd -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\linalg.pxd -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\structs.pxd -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\typedefs.pxd -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\__init__.pxd -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\compile_time_constants.pxi -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\linalg.cpp -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\structs.cpp -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\typedefs.cpp -> build\\lib.win-amd64-cpython-311\\thinc\n",
      "            copying thinc\\linear\\avgtron.pyx -> build\\lib.win-amd64-cpython-311\\thinc\\linear\n",
      "            copying thinc\\linear\\features.pyx -> build\\lib.win-amd64-cpython-311\\thinc\\linear\n",
      "            copying thinc\\linear\\linear.pyx -> build\\lib.win-amd64-cpython-311\\thinc\\linear\n",
      "            copying thinc\\linear\\serialize.pyx -> build\\lib.win-amd64-cpython-311\\thinc\\linear\n",
      "            copying thinc\\linear\\sparse.pyx -> build\\lib.win-amd64-cpython-311\\thinc\\linear\n",
      "            copying thinc\\linear\\avgtron.pxd -> build\\lib.win-amd64-cpython-311\\thinc\\linear\n",
      "            copying thinc\\linear\\features.pxd -> build\\lib.win-amd64-cpython-311\\thinc\\linear\n",
      "            copying thinc\\linear\\serialize.pxd -> build\\lib.win-amd64-cpython-311\\thinc\\linear\n",
      "            copying thinc\\linear\\sparse.pxd -> build\\lib.win-amd64-cpython-311\\thinc\\linear\n",
      "            copying thinc\\linear\\__init__.pxd -> build\\lib.win-amd64-cpython-311\\thinc\\linear\n",
      "            copying thinc\\linear\\avgtron.cpp -> build\\lib.win-amd64-cpython-311\\thinc\\linear\n",
      "            copying thinc\\linear\\features.cpp -> build\\lib.win-amd64-cpython-311\\thinc\\linear\n",
      "            copying thinc\\linear\\linear.cpp -> build\\lib.win-amd64-cpython-311\\thinc\\linear\n",
      "            copying thinc\\linear\\serialize.cpp -> build\\lib.win-amd64-cpython-311\\thinc\\linear\n",
      "            copying thinc\\linear\\sparse.cpp -> build\\lib.win-amd64-cpython-311\\thinc\\linear\n",
      "            copying thinc\\neural\\ops.pyx -> build\\lib.win-amd64-cpython-311\\thinc\\neural\n",
      "            copying thinc\\neural\\optimizers.pyx -> build\\lib.win-amd64-cpython-311\\thinc\\neural\n",
      "            copying thinc\\neural\\_aligned_alloc.pyx -> build\\lib.win-amd64-cpython-311\\thinc\\neural\n",
      "            copying thinc\\neural\\cpu.pxd -> build\\lib.win-amd64-cpython-311\\thinc\\neural\n",
      "            copying thinc\\neural\\ops.pxd -> build\\lib.win-amd64-cpython-311\\thinc\\neural\n",
      "            copying thinc\\neural\\__init__.pxd -> build\\lib.win-amd64-cpython-311\\thinc\\neural\n",
      "            copying thinc\\neural\\ops.cpp -> build\\lib.win-amd64-cpython-311\\thinc\\neural\n",
      "            copying thinc\\neural\\optimizers.cpp -> build\\lib.win-amd64-cpython-311\\thinc\\neural\n",
      "            copying thinc\\neural\\_aligned_alloc.cpp -> build\\lib.win-amd64-cpython-311\\thinc\\neural\n",
      "            copying thinc\\extra\\cache.pyx -> build\\lib.win-amd64-cpython-311\\thinc\\extra\n",
      "            copying thinc\\extra\\eg.pyx -> build\\lib.win-amd64-cpython-311\\thinc\\extra\n",
      "            copying thinc\\extra\\mb.pyx -> build\\lib.win-amd64-cpython-311\\thinc\\extra\n",
      "            copying thinc\\extra\\search.pyx -> build\\lib.win-amd64-cpython-311\\thinc\\extra\n",
      "            copying thinc\\extra\\cache.pxd -> build\\lib.win-amd64-cpython-311\\thinc\\extra\n",
      "            copying thinc\\extra\\eg.pxd -> build\\lib.win-amd64-cpython-311\\thinc\\extra\n",
      "            copying thinc\\extra\\mb.pxd -> build\\lib.win-amd64-cpython-311\\thinc\\extra\n",
      "            copying thinc\\extra\\search.pxd -> build\\lib.win-amd64-cpython-311\\thinc\\extra\n",
      "            copying thinc\\extra\\__init__.pxd -> build\\lib.win-amd64-cpython-311\\thinc\\extra\n",
      "            copying thinc\\extra\\cache.cpp -> build\\lib.win-amd64-cpython-311\\thinc\\extra\n",
      "            copying thinc\\extra\\eg.cpp -> build\\lib.win-amd64-cpython-311\\thinc\\extra\n",
      "            copying thinc\\extra\\mb.cpp -> build\\lib.win-amd64-cpython-311\\thinc\\extra\n",
      "            copying thinc\\extra\\search.cpp -> build\\lib.win-amd64-cpython-311\\thinc\\extra\n",
      "            running build_ext\n",
      "            building 'thinc.linalg' extension\n",
      "            creating build\\temp.win-amd64-cpython-311\n",
      "            creating build\\temp.win-amd64-cpython-311\\Release\n",
      "            creating build\\temp.win-amd64-cpython-311\\Release\\thinc\n",
      "            \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.39.33519\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -Ic:\\Users\\ammar\\anaconda3\\include -IC:\\Users\\ammar\\AppData\\Local\\Temp\\pip-install-p4j9hszz\\thinc_f35a46716b124d83ab616622fb81d983\\include -Ic:\\Users\\ammar\\anaconda3\\include -Ic:\\Users\\ammar\\anaconda3\\Include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.39.33519\\include\" \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Auxiliary\\VS\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22621.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\cppwinrt\" /EHsc /Tpthinc/linalg.cpp /Fobuild\\temp.win-amd64-cpython-311\\Release\\thinc/linalg.obj /Ox /EHsc\n",
      "            linalg.cpp\n",
      "            thinc/linalg.cpp(196): fatal error C1083: Cannot open include file: 'longintrepr.h': No such file or directory\n",
      "            error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2022\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.39.33519\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
      "            [end of output]\n",
      "      \n",
      "        note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "        ERROR: Failed building wheel for thinc\n",
      "        Running setup.py clean for thinc\n",
      "        Building wheel for blis (setup.py): started\n",
      "        Building wheel for blis (setup.py): finished with status 'error'\n",
      "        error: subprocess-exited-with-error\n",
      "      \n",
      "        Ã— python setup.py bdist_wheel did not run successfully.\n",
      "        â”‚ exit code: 1\n",
      "        â•°â”€> [35 lines of output]\n",
      "            BLIS_COMPILER? None\n",
      "            c:\\Users\\ammar\\anaconda3\\Lib\\site-packages\\setuptools\\__init__.py:80: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "            !!\n",
      "      \n",
      "                    ********************************************************************************\n",
      "                    Requirements should be satisfied by a PEP 517 installer.\n",
      "                    If you are using pip, you can try `pip install --use-pep517`.\n",
      "                    ********************************************************************************\n",
      "      \n",
      "            !!\n",
      "              dist.fetch_build_eggs(dist.setup_requires)\n",
      "            running bdist_wheel\n",
      "            running build\n",
      "            running build_py\n",
      "            creating build\n",
      "            creating build\\lib.win-amd64-cpython-311\n",
      "            creating build\\lib.win-amd64-cpython-311\\blis\n",
      "            copying blis\\about.py -> build\\lib.win-amd64-cpython-311\\blis\n",
      "            copying blis\\benchmark.py -> build\\lib.win-amd64-cpython-311\\blis\n",
      "            copying blis\\__init__.py -> build\\lib.win-amd64-cpython-311\\blis\n",
      "            creating build\\lib.win-amd64-cpython-311\\blis\\tests\n",
      "            copying blis\\tests\\common.py -> build\\lib.win-amd64-cpython-311\\blis\\tests\n",
      "            copying blis\\tests\\test_dotv.py -> build\\lib.win-amd64-cpython-311\\blis\\tests\n",
      "            copying blis\\tests\\test_gemm.py -> build\\lib.win-amd64-cpython-311\\blis\\tests\n",
      "            copying blis\\tests\\__init__.py -> build\\lib.win-amd64-cpython-311\\blis\\tests\n",
      "            copying blis\\cy.pyx -> build\\lib.win-amd64-cpython-311\\blis\n",
      "            copying blis\\py.pyx -> build\\lib.win-amd64-cpython-311\\blis\n",
      "            copying blis\\cy.pxd -> build\\lib.win-amd64-cpython-311\\blis\n",
      "            copying blis\\__init__.pxd -> build\\lib.win-amd64-cpython-311\\blis\n",
      "            running build_ext\n",
      "            msvc\n",
      "            py_compiler msvc\n",
      "            {'LS_COLORS': 'rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.Z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:', 'HOSTTYPE': 'x86_64', 'LESSCLOSE': '/usr/bin/lesspipe %s %s', 'LANG': 'C.UTF-8', 'OLDPWD': '/home/matt/repos/flame-blis', 'VIRTUAL_ENV': '/home/matt/repos/cython-blis/env3.6', 'USER': 'matt', 'PWD': '/home/matt/repos/cython-blis', 'HOME': '/home/matt', 'NAME': 'LAPTOP-OMKOB3VM', 'XDG_DATA_DIRS': '/usr/local/share:/usr/share:/var/lib/snapd/desktop', 'SHELL': '/bin/bash', 'TERM': 'xterm-256color', 'SHLVL': '1', 'LOGNAME': 'matt', 'PATH': '/home/matt/repos/cython-blis/env3.6/bin:/tmp/google-cloud-sdk/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/mnt/c/Users/matt/Documents/cmder/vendor/conemu-maximus5/ConEmu/Scripts:/mnt/c/Users/matt/Documents/cmder/vendor/conemu-maximus5:/mnt/c/Users/matt/Documents/cmder/vendor/conemu-maximus5/ConEmu:/mnt/c/Python37/Scripts:/mnt/c/Python37:/mnt/c/Program Files (x86)/Intel/Intel(R) Management Engine Components/iCLS:/mnt/c/Program Files/Intel/Intel(R) Management Engine Components/iCLS:/mnt/c/Windows/System32:/mnt/c/Windows:/mnt/c/Windows/System32/wbem:/mnt/c/Windows/System32/WindowsPowerShell/v1.0:/mnt/c/Program Files (x86)/Intel/Intel(R) Management Engine Components/DAL:/mnt/c/Program Files/Intel/Intel(R) Management Engine Components/DAL:/mnt/c/Program Files (x86)/Intel/Intel(R) Management Engine Components/IPT:/mnt/c/Program Files/Intel/Intel(R) Management Engine Components/IPT:/mnt/c/Program Files/Intel/WiFi/bin:/mnt/c/Program Files/Common Files/Intel/WirelessCommon:/mnt/c/Program Files (x86)/NVIDIA Corporation/PhysX/Common:/mnt/c/ProgramData/chocolatey/bin:/mnt/c/Program Files/Git/cmd:/mnt/c/Program Files/LLVM/bin:/mnt/c/Windows/System32:/mnt/c/Windows:/mnt/c/Windows/System32/wbem:/mnt/c/Windows/System32/WindowsPowerShell/v1.0:/mnt/c/Windows/System32/OpenSSH:/mnt/c/Program Files/nodejs:/mnt/c/Users/matt/AppData/Local/Microsoft/WindowsApps:/mnt/c/Users/matt/AppData/Local/Programs/Microsoft VS Code/bin:/mnt/c/Users/matt/AppData/Roaming/npm:/snap/bin:/mnt/c/Program Files/Oracle/VirtualBox', 'PS1': '(env3.6) \\\\[\\\\e]0;\\\\u@\\\\h: \\\\w\\\\a\\\\]${debian_chroot:+($debian_chroot)}\\\\[\\\\033[01;32m\\\\]\\\\u@\\\\h\\\\[\\\\033[00m\\\\]:\\\\[\\\\033[01;34m\\\\]\\\\w\\\\[\\\\033[00m\\\\]\\\\$ ', 'VAGRANT_HOME': '/home/matt/.vagrant.d/', 'LESSOPEN': '| /usr/bin/lesspipe %s', '_': '/home/matt/repos/cython-blis/env3.6/bin/python'}\n",
      "            clang -c C:\\Users\\ammar\\AppData\\Local\\Temp\\pip-install-p4j9hszz\\blis_79aa8144454044ee88142e4c0fe45b61\\blis\\_src\\config\\bulldozer\\bli_cntx_init_bulldozer.c -o C:\\Users\\ammar\\AppData\\Local\\Temp\\tmpzv3zdr6t\\bli_cntx_init_bulldozer.o -O2 -funroll-all-loops -std=c99 -D_POSIX_C_SOURCE=200112L -DBLIS_VERSION_STRING=\"0.5.0-6\" -DBLIS_IS_BUILDING_LIBRARY -Iinclude\\windows-x86_64 -I.\\frame\\3\\ -I.\\frame\\ind\\ukernels\\ -I.\\frame\\1m\\ -I.\\frame\\1f\\ -I.\\frame\\1\\ -I.\\frame\\include -IC:\\Users\\ammar\\AppData\\Local\\Temp\\pip-install-p4j9hszz\\blis_79aa8144454044ee88142e4c0fe45b61\\blis\\_src\\include\\windows-x86_64\n",
      "            error: [WinError 2] The system cannot find the file specified\n",
      "            [end of output]\n",
      "      \n",
      "        note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "        ERROR: Failed building wheel for blis\n",
      "        Running setup.py clean for blis\n",
      "      Failed to build preshed thinc blis\n",
      "      ERROR: Could not build wheels for preshed, thinc, blis, which is required to install pyproject.toml-based projects\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× pip subprocess to install build dependencies did not run successfully.\n",
      "│ exit code: 1\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting allennlp\n",
      "  Using cached allennlp-2.10.1-py3-none-any.whl.metadata (21 kB)\n",
      "INFO: pip is looking at multiple versions of allennlp to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached allennlp-2.10.0-py3-none-any.whl.metadata (20 kB)\n",
      "  Using cached allennlp-2.9.3-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached allennlp-2.9.2-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached allennlp-2.9.1-py3-none-any.whl.metadata (19 kB)\n",
      "  Using cached allennlp-2.9.0-py3-none-any.whl.metadata (18 kB)\n",
      "  Using cached allennlp-2.8.0-py3-none-any.whl.metadata (17 kB)\n",
      "  Using cached allennlp-2.7.0-py3-none-any.whl.metadata (17 kB)\n",
      "INFO: pip is still looking at multiple versions of allennlp to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached allennlp-2.6.0-py3-none-any.whl.metadata (17 kB)\n",
      "  Using cached allennlp-2.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "  Using cached allennlp-2.4.0-py3-none-any.whl.metadata (17 kB)\n",
      "  Using cached allennlp-2.3.1-py3-none-any.whl.metadata (17 kB)\n",
      "  Using cached allennlp-2.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached allennlp-2.2.0-py3-none-any.whl.metadata (17 kB)\n",
      "  Using cached allennlp-2.1.0-py3-none-any.whl.metadata (17 kB)\n",
      "  Using cached allennlp-2.0.1-py3-none-any.whl.metadata (15 kB)\n",
      "  Using cached allennlp-2.0.0-py3-none-any.whl.metadata (15 kB)\n",
      "  Using cached allennlp-1.5.0-py3-none-any.whl.metadata (15 kB)\n",
      "  Using cached allennlp-1.4.1-py3-none-any.whl.metadata (15 kB)\n",
      "  Using cached allennlp-1.4.0-py3-none-any.whl.metadata (15 kB)\n",
      "  Using cached allennlp-1.3.0-py3-none-any.whl.metadata (15 kB)\n",
      "  Using cached allennlp-1.2.2-py3-none-any.whl.metadata (15 kB)\n",
      "  Using cached allennlp-1.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "  Using cached allennlp-1.2.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached allennlp-1.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached allennlp-1.0.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Using cached allennlp-0.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: torch>=1.2.0 in c:\\users\\ammar\\anaconda3\\lib\\site-packages (from allennlp) (2.2.1)\n",
      "Requirement already satisfied: overrides in c:\\users\\ammar\\anaconda3\\lib\\site-packages (from allennlp) (7.4.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\ammar\\anaconda3\\lib\\site-packages (from allennlp) (3.8.1)\n",
      "Collecting spacy<2.2,>=2.1.0 (from allennlp)\n",
      "  Using cached spacy-2.1.9.tar.gz (30.7 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'error'\n"
     ]
    }
   ],
   "source": [
    "!pip install --use-pep517 allennlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x glove.6B.50d.txt\n",
      "x glove.6B.100d.txt\n",
      "x glove.6B.200d.txt\n",
      "x glove.6B.300d.txt\n"
     ]
    }
   ],
   "source": [
    "!tar -xvzf glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import fasttext.util\n",
    "from allennlp.commands.elmo import ElmoEmbedder\n",
    "\n",
    "# Load the data\n",
    "url = 'https://raw.githubusercontent.com/MuhammadYaseenKhan/Urdu-Sentiment-Corpus/master/urdu-sentiment-corpus-v1.tsv'\n",
    "df = pd.read_csv(url, delimiter='\\t')\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(df, test_size=0.25, random_state=42)\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(train_data['text'])\n",
    "\n",
    "# Convert the text data into sequences of integers\n",
    "train_sequences = tokenizer.texts_to_sequences(train_data['text'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_data['text'])\n",
    "\n",
    "# Pad the sequences\n",
    "train_data = pad_sequences(train_sequences, maxlen=100)\n",
    "test_data = pad_sequences(test_sequences, maxlen=100)\n",
    "\n",
    "# Train a Word2Vec model\n",
    "word2vec = Word2Vec(train_data['text'], size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Load the GloVe embeddings\n",
    "glove = KeyedVectors.load_word2vec_format('glove.6B.100d.txt', binary=False)\n",
    "\n",
    "# Train a FastText model\n",
    "fasttext.util.download_model('en', if_exists='ignore')\n",
    "ft = fasttext.load_model('cc.en.300.bin')\n",
    "\n",
    "# Initialize the ELMo embedder\n",
    "elmo = ElmoEmbedder()\n",
    "\n",
    "# Create the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000, output_dim=100, input_length=100))\n",
    "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_data, train_labels, epochs=10, validation_data=(test_data, test_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy, precision, recall, f_score = evaluate(model, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
